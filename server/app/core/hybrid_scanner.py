import os
import logging
import concurrent.futures
from typing import List, Dict, Tuple
from pathlib import Path

from app.core.static_analyzer import StaticAnalyzer
from app.llm.engine import LLMEngine
from app.models.issue import IssueCandidate

logger = logging.getLogger("app.hybrid_scanner")

class HybridScanner:
    """
    Two-stage hybrid scanning pipeline:
    Stage 1: Fast static analysis pre-filter (regex patterns)
    Stage 2: LLM validation on flagged files only
    
    This approach provides 5-10x speedup while maintaining accuracy.
    """
    
    def __init__(self, project_path: str, llm_model: str = "llama3.1:8b"):
        self.project_path = project_path
        self.llm_model = llm_model
        self.static_analyzer = StaticAnalyzer()
        self.llm_engine = LLMEngine(provider=llm_model)
        
        self.supported_extensions = {'.py', '.js', '.jsx', '.ts', '.tsx', '.java', '.go', '.rs', '.cpp', '.c', '.h'}
        self.excluded_dirs = {
            '.git', '.venv', 'venv', 'env', 'node_modules', 'dist', 'build', 
            '__pycache__', 'target', '.idea', '.vscode', '.tox', 'coverage', 
            'tmp', 'temp', 'logs', 'vendor', 'bin', 'obj', '.next', '.nuxt'
        }
        self.files_to_scan: List[str] = []
        
        # Statistics
        self.stats = {
            'total_files': 0,
            'clean_files': 0,
            'flagged_files': 0,
            'static_findings': 0,
            'llm_validated_issues': 0
        }
    
    def discover_files(self) -> List[str]:
        """Recursively discover files to scan."""
        logger.info(f"ðŸ” Discovering files in {self.project_path}...")
        self.files_to_scan = []
        
        excluded_dirs_lower = {d.lower() for d in self.excluded_dirs}
        
        for root, dirs, files in os.walk(self.project_path):
            # Modify dirs in-place to skip excluded directories
            original_dirs = list(dirs)
            dirs[:] = []
            for d in original_dirs:
                if d.lower() not in excluded_dirs_lower:
                    dirs.append(d)
                else:
                    logger.debug(f"Skipping excluded directory: {os.path.join(root, d)}")
            
            for file in files:
                ext = os.path.splitext(file)[1].lower()
                if ext in self.supported_extensions:
                    self.files_to_scan.append(os.path.join(root, file))
        
        self.stats['total_files'] = len(self.files_to_scan)
        logger.info(f"ðŸ“‚ Found {len(self.files_to_scan)} supported files to scan")
        return self.files_to_scan
    
    def scan(self) -> List[IssueCandidate]:
        """
        Execute hybrid scanning pipeline:
        1. Discover all files
        2. Static analysis pre-filter (fast)
        3. LLM validation (selective)
        """
        self.discover_files()
        
        if not self.files_to_scan:
            logger.warning("âš ï¸  No files found to scan")
            return []
        
        # Stage 1: Static analysis pre-filter
        logger.info("âš¡ Stage 1: Static analysis pre-filter...")
        flagged_files = self._static_prefilter()
        
        reduction = len(self.files_to_scan) - len(flagged_files)
        reduction_pct = (reduction / len(self.files_to_scan) * 100) if self.files_to_scan else 0
        
        logger.info(f"âœ… Filtered out {reduction} clean files ({reduction_pct:.1f}%)")
        logger.info(f"ðŸŽ¯ {len(flagged_files)} files flagged for LLM validation")
        
        self.stats['clean_files'] = reduction
        self.stats['flagged_files'] = len(flagged_files)
        
        if not flagged_files:
            logger.info("ðŸŽ‰ No suspicious patterns found. Project looks clean!")
            return []
        
        # Stage 2: LLM validation only on flagged files
        logger.info(f"ðŸ¤– Stage 2: LLM deep analysis on {len(flagged_files)} files...")
        all_issues = []
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
            future_to_file = {
                executor.submit(self._llm_validate, fp, data): fp 
                for fp, data in flagged_files.items()
            }
            
            completed = 0
            for future in concurrent.futures.as_completed(future_to_file):
                file_path = future_to_file[future]
                completed += 1
                
                try:
                    issues = future.result()
                    all_issues.extend(issues)
                    
                    file_name = Path(file_path).name
                    logger.info(f"  [{completed}/{len(flagged_files)}] âœ“ {file_name}: {len(issues)} issues")
                    
                except Exception as e:
                    file_name = Path(file_path).name
                    logger.error(f"  [{completed}/{len(flagged_files)}] âœ— {file_name}: Error - {e}")
        
        self.stats['llm_validated_issues'] = len(all_issues)
        
        logger.info(f"\nðŸŽ‰ Hybrid scan complete!")
        logger.info(f"ðŸ“Š Statistics:")
        logger.info(f"   - Total files scanned: {self.stats['total_files']}")
        logger.info(f"   - Clean files (skipped LLM): {self.stats['clean_files']}")
        logger.info(f"   - Static findings: {self.stats['static_findings']}")
        logger.info(f"   - LLM validated issues: {self.stats['llm_validated_issues']}")
        
        return all_issues
    
    def _static_prefilter(self) -> Dict[str, Tuple[str, List[Dict]]]:
        """
        Stage 1: Fast static analysis on all files.
        Returns: Dict of flagged files with their content and findings
        """
        flagged = {}
        total_static_findings = 0
        
        for file_path in self.files_to_scan:
            try:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                
                # Quick pattern matching
                findings = self.static_analyzer.quick_scan(file_path, content)
                total_static_findings += len(findings)
                
                # Flag file if it has Critical/High severity findings
                if self.static_analyzer.should_scan_with_llm(findings):
                    flagged[file_path] = (content, findings)
                    
                    # Log what was found
                    file_name = Path(file_path).name
                    logger.debug(f"ðŸš© Flagged {file_name}: {len(findings)} static findings")
                
            except Exception as e:
                logger.warning(f"âš ï¸  Error reading {file_path}: {e}")
        
        self.stats['static_findings'] = total_static_findings
        return flagged
    
    def _llm_validate(self, file_path: str, data: Tuple[str, List[Dict]]) -> List[IssueCandidate]:
        """
        Stage 2: LLM validation with context from static analysis.
        The LLM receives hints about suspicious lines to focus on.
        """
        content, static_findings = data
        
        # Build context hint for LLM
        context = self._build_llm_context(static_findings)
        
        # Call LLM with enhanced prompt
        try:
            issues = self.llm_engine.scan_file(file_path, content, context=context)
            return issues
        except Exception as e:
            logger.error(f"LLM validation failed for {file_path}: {e}")
            return []
    
    def _build_llm_context(self, findings: List[Dict]) -> str:
        """
        Build context hint for LLM from static analysis findings.
        This helps the LLM focus on the most suspicious areas.
        """
        if not findings:
            return ""
        
        # Limit to top 10 most critical findings
        critical_findings = sorted(
            findings, 
            key=lambda x: {'Critical': 0, 'High': 1, 'Medium': 2, 'Low': 3}.get(x['severity'], 4)
        )[:10]
        
        lines = [
            f"Line {f['line']}: Possible {f['type']} ({f['severity']})"
            for f in critical_findings
        ]
        
        return f"\nðŸŽ¯ Static analysis flagged these lines (validate these carefully):\n" + "\n".join(lines)
    
    def get_scan_statistics(self) -> Dict:
        """Get detailed scan statistics"""
        return {
            **self.stats,
            'speedup_factor': round(self.stats['total_files'] / max(self.stats['flagged_files'], 1), 2),
            'efficiency': f"{self.stats['clean_files'] / max(self.stats['total_files'], 1) * 100:.1f}%"
        }
